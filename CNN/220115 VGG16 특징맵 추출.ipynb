{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12437c06",
   "metadata": {},
   "source": [
    "# 사전학습된 VGG16에서 특징맵 추출하기\n",
    "\n",
    "CNN 모델의 Architecture은 크게 \n",
    "1. Localization 작업 수행(Feature map extraction) \n",
    "2. Classification 작업 수행\n",
    "\n",
    "으로 이루어진다.\n",
    "\n",
    "<전체>\n",
    "\n",
    "이미지의 특징맵을 추출하고 추출된 특징맵을 사용자 입력 이미지와 유사도 계산을 통해 유사도가 가장 높은 앨범 이미지 10개를 출력하고자 한다.\n",
    "\n",
    "\n",
    "이 코드는 단순하게 이미지의 특징맵을 추출하는 과정이다.\n",
    "\n",
    "참고(https://deep-eye.tistory.com/14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cf2d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.python.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.python.keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f213417b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "base_model = VGG16(weights='imagenet')\n",
    "# 모델 확인하기\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a0eab8",
   "metadata": {},
   "source": [
    "합성곱층은 여러가지 필터를 가지고 필터마다 하나의 특성 맵을 출력한다.\n",
    "여러 특성 맵을 쌓는 것이 더 좋다.\n",
    "즉 하나의 합성곱 층이 입력에 여러 필터를 동시 적용하여 입력에 있는 여러 특성을 감지할 수 있다.\n",
    "\n",
    "위의 VGG16 모델을 확인해봤을 때 feature map 추출에 관련없는 층인 flatten, 완전연결층(fully connected - Dense ), prediction layer은 잘라준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1526d370",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Feature Map 추출 모델 생성\n",
    "#get_layer('추출 원하는 레이어 이름').output으로 마지막 conv layer 와 가까운 층 선택\n",
    "model = Model(inputs = base_model.input,outputs = base_model.get_layer('block5_pool').output)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4418f905",
   "metadata": {},
   "source": [
    "일단 7*7*512 크기의 feature를 vae(평균과 분산을 알려주는)를 사용하기 위해선 더 압축해야하고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b33cbb",
   "metadata": {},
   "source": [
    "### 특징맵으로 추출할 이미지 가져오기\n",
    "\n",
    "일단 relaxed 폴더에 있는 모든 이미지를 가져오기 전, 하나의 이미지에 대해 특징맵이 제대로 추출되는지 확인한다.\n",
    "\n",
    "입력 이미지에 대해 전처리를 해준다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "593002bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 영상 전처리\n",
    "image = cv2.imread(\"C:/Users/minki/Desktop/2022CUAI_winter/image2.jpg\")\n",
    "# 학습 모델에 맞게 영상 크기 수정\n",
    "image = cv2.resize(image,dsize=(224,224))\n",
    "image = img_to_array(image)\n",
    "image = image.reshape((1, image.shape[0],image.shape[1],image.shape[2]))\n",
    "image = preprocess_input(image)\n",
    "# Feature Map 추출\n",
    "feature_map = model.predict(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a446fd",
   "metadata": {},
   "source": [
    "Feature map을 확인해본다,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d250b1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ]],\n",
       "\n",
       "        [[ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ]],\n",
       "\n",
       "        [[ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           5.0650845,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       , 12.639103 , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  7.7767982],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       ,  8.534249 , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       , 37.240593 , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ]],\n",
       "\n",
       "        [[ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       , 22.838453 ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       , 22.497423 ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       , 15.786415 ],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  1.1466854,\n",
       "          14.182962 , 51.833363 ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ]],\n",
       "\n",
       "        [[ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ,  0.       , ...,  0.       ,\n",
       "           0.       ,  0.       ]]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62dadee",
   "metadata": {},
   "source": [
    "Plot으로 특징맵 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8610457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 크기 square x square\n",
    "square = 4\n",
    "ix = 1\n",
    "for i in range(square):\n",
    "    for j in range(square):\n",
    "        ax = pyplot.subplot(square,square,ix)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        # Feature Map\n",
    "        pyplot.imshow(feature_map[0,:,:,ix-1])\n",
    "        ix = ix + 1\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6973ded8",
   "metadata": {},
   "source": [
    "2. 특징 추출 모델로 전이학습한 뒤, 평균과 분산을 출력하는 Variational AutoEncoder (vae) 모델을 사용해 이를 latent vector 로 압축한다.\n",
    "\n",
    "3. 거리 파악 기술\n",
    "latent vector 값의 거리를 구하는게 유사도임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3076f53",
   "metadata": {},
   "source": [
    "## VAE 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c719dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "    super(CVAE, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            # No activation\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "        ]\n",
    "    )\n",
    "    #기본적으론 vae를 다 사용해서 나온 재구성된 이미지를 다시 인코딩해서 그렇게 나온 latent vector를 거리 계산해서 사용한다.\n",
    "    #하지만.. 시간이 없기 때문에 vae모델의 중간에서 latent vector가 나올 때를 끊어서 차원 축소된 vector를 \n",
    "\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(7, 7, 32)),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=3, strides=2, padding='same',\n",
    "                activation='relu'),\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=1, kernel_size=3, strides=1, padding='same'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "  @tf.function\n",
    "  def sample(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "    return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "  def encode(self, x):\n",
    "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
